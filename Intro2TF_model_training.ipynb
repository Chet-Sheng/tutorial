{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training a model in TF\n",
    "\n",
    "This notebook contains an example of how to speficy and train a model in TensorFlow.\n",
    "\n",
    "1. Building the model\n",
    "2. Specifying a cost/loss function and an optimizer (in this case SGD)\n",
    "3. Launch a session to do the actual training\n",
    "\n",
    "[Bonus] Define variables you want to track during learning. And see how you can use TensorBoard to monitor your training.\n",
    "\n",
    "This is a starter code/example. So feel free to play around with these functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for compatibility \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn import datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# split into input data (x) and GT labels (y)\n",
    "data_x = dataset.data\n",
    "data_y = dataset.target\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into testing and training data. We shuffle the data first, as the dataset is ordered in terms of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_indices = np.random.permutation(data_y.shape[0])\n",
    "\n",
    "train_x = data_x[new_indices[:125],:]\n",
    "train_y = data_y[new_indices[:125]]\n",
    "\n",
    "test_x = data_x[new_indices[125:],:]\n",
    "test_y = data_y[new_indices[125:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Building the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# placeholder for data x (4 attributes), one prediction label\n",
    "x    = tf.placeholder(\"float\", shape=[None, 4])\n",
    "y_GT = tf.placeholder(\"int64\", shape=[None, ])\n",
    "\n",
    "# model parameters\n",
    "n_hidden = 100\n",
    "W_h = tf.Variable(0.1*tf.random_normal([4, n_hidden]), name=\"W_h\")\n",
    "b_h = tf.Variable(tf.random_normal([n_hidden]), name=\"b_h\")\n",
    "hidden_layer = tf.matmul(x, W_h) + b_h\n",
    "\n",
    "# model parameters\n",
    "W = tf.Variable(0.1*tf.random_normal([n_hidden, 3]), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([3]), name=\"b\")\n",
    "\n",
    "# putting the model together\n",
    "z = tf.matmul(hidden_layer, W) + b\n",
    "y = tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Specify loss and training/optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one-hot encoding of the class labels\n",
    "y_GT_one_hot  = tf.one_hot(y_GT, depth=3)\n",
    "\n",
    "# cross-entropy loss\n",
    "cross_entropy = -tf.reduce_sum(y_GT_one_hot * tf.log(y+1e-10))\n",
    "\n",
    "# alternative implementation of cross-entropy in tf. (a bit more stable numerical)\n",
    "#cross_entropy = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=Y_GT_one_hot, logits=z)\n",
    "\n",
    "# define optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_op = opt.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Neg:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Launch a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create operation to inialize all variables\n",
    "init_op = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x7fbc2ca1dd90>\n"
     ]
    }
   ],
   "source": [
    "# launch session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print(W)\n",
    "    #print sess.run(W) #print W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342.77\n"
     ]
    }
   ],
   "source": [
    "# one step of training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # one step training -- repeat this to fully optimize\n",
    "    sess.run(train_op, feed_dict={x: data_x, y_GT: data_y})\n",
    "    \n",
    "    xen = sess.run(cross_entropy, feed_dict={x: data_x, y_GT: data_y})\n",
    "    print(xen)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding summary variables that want to track during training\n",
    "\n",
    "We will track the cross-entropy, and accuracy. The log files will be saves in a separate folder **\\tf_logs**.\n",
    "\n",
    "To visualize the plots/learning curves, go to your terminal and execute:\n",
    "\n",
    "```\n",
    ">> tensorboard --logdir=\"\\tf_logs\"\n",
    "```\n",
    "\n",
    "And then open your browser(preferably Chrome) and navigate to: http://127.0.1.1:6006.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the accuracy \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_GT, tf.argmax(y, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summary \n",
    "tf.scalar_summary(\"cross_entropy\", cross_entropy)\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   0 -- Cross-entropy: 179.825623\n",
      "Iter   0 -- Accuracy: 0.360000\n",
      "Iter  10 -- Cross-entropy: 9.767296\n",
      "Iter  10 -- Accuracy: 0.960000\n",
      "Iter  20 -- Cross-entropy: 7.014232\n",
      "Iter  20 -- Accuracy: 0.960000\n",
      "Iter  30 -- Cross-entropy: 5.565076\n",
      "Iter  30 -- Accuracy: 0.960000\n",
      "Iter  40 -- Cross-entropy: 4.591428\n",
      "Iter  40 -- Accuracy: 0.960000\n",
      "Iter  50 -- Cross-entropy: 3.880028\n",
      "Iter  50 -- Accuracy: 0.960000\n",
      "Iter  60 -- Cross-entropy: 3.360386\n",
      "Iter  60 -- Accuracy: 0.960000\n",
      "Iter  70 -- Cross-entropy: 13.685889\n",
      "Iter  70 -- Accuracy: 0.720000\n",
      "Iter  80 -- Cross-entropy: 5.321474\n",
      "Iter  80 -- Accuracy: 0.880000\n",
      "Iter  90 -- Cross-entropy: 5.777423\n",
      "Iter  90 -- Accuracy: 0.880000\n",
      "Iter 100 -- Cross-entropy: 5.502826\n",
      "Iter 100 -- Accuracy: 0.880000\n",
      "Iter 110 -- Cross-entropy: 5.147684\n",
      "Iter 110 -- Accuracy: 0.880000\n",
      "Iter 120 -- Cross-entropy: 5.065189\n",
      "Iter 120 -- Accuracy: 0.880000\n",
      "Iter 130 -- Cross-entropy: 4.779284\n",
      "Iter 130 -- Accuracy: 0.920000\n",
      "Iter 140 -- Cross-entropy: 4.528471\n",
      "Iter 140 -- Accuracy: 0.920000\n",
      "Iter 150 -- Cross-entropy: 4.338633\n",
      "Iter 150 -- Accuracy: 0.920000\n",
      "Iter 160 -- Cross-entropy: 4.097877\n",
      "Iter 160 -- Accuracy: 0.920000\n",
      "Iter 170 -- Cross-entropy: 3.804062\n",
      "Iter 170 -- Accuracy: 0.920000\n",
      "Iter 180 -- Cross-entropy: 3.514620\n",
      "Iter 180 -- Accuracy: 0.920000\n",
      "Iter 190 -- Cross-entropy: 3.252710\n",
      "Iter 190 -- Accuracy: 0.960000\n"
     ]
    }
   ],
   "source": [
    "# multiple steps of training\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    summary_writer  = tf.train.SummaryWriter('tf_logs', sess.graph)\n",
    "    for iterIndex in range(200):\n",
    "        sess.run(train_op, feed_dict={x: train_x, y_GT: train_y})\n",
    "        \n",
    "        summary = sess.run(summary_op, feed_dict={x: train_x, y_GT: train_y})\n",
    "        summary_writer.add_summary(summary, iterIndex)\n",
    "        \n",
    "        if iterIndex%10==0:\n",
    "            \n",
    "            xen = sess.run(cross_entropy, feed_dict={x: test_x, y_GT: test_y})\n",
    "            print(\"Iter %3d -- Cross-entropy: %f\"%(iterIndex,xen))\n",
    "            \n",
    "            acc = sess.run(accuracy, feed_dict={x: test_x, y_GT: test_y})\n",
    "            print(\"Iter %3d -- Accuracy: %f\"%(iterIndex,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting results\n",
    "\n",
    "Here are some suggestions of experiments to test your understanding and intuition:\n",
    "    \n",
    "* Look at the progression of the loss/accuracy within training. What do you observe? Is that what you expected?\n",
    "\n",
    "* Re-run the training with minibatches - aka each update in the training step will look only at a small sample of the data. \n",
    "Run this for minibatches of size $1, 5, 10$.\n",
    "\n",
    "* Re-run the training above with a smaller sample size. Say $10$ training examples.\n",
    "\n",
    "* Try deeper/shallower models. More neurons.\n",
    "\n",
    "This is a very small dataset, not ideal for deep learning, but you will get results instantenously and will hopefully help you build some intuition around the training process + building and optimizing models in TF.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
